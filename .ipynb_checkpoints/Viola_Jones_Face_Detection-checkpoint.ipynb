{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import pickle \n",
    "import random\n",
    "\n",
    "for typ in ['trainset','testset']:\n",
    "    input_data = []\n",
    "    for f in ['faces','non-faces']:\n",
    "        label = 1 if f =='faces' else 0\n",
    "        typ_dir=\"../VJ_dataset/\"+typ+\"/\"+f+\"/\"\n",
    "        images=os.listdir(typ_dir) # list of file names\n",
    "\n",
    "        for x in images:\n",
    "            im = cv2.imread(typ_dir+\"/\"+x,0)\n",
    "            input_data.append((im,label)) # (image matrix, label (1 or 0))\n",
    "    random.shuffle(input_data)\n",
    "    file=open(typ[:-3]+'ing_data.pkl','wb')\n",
    "    pickle.dump(input_data,file)\n",
    "    print(\"Size of {}ing input data : {}\".format(typ[:-3],len(input_data)))\n",
    "    print(\"DONE\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integralImage(i_origianl):\n",
    "    # integral image at location x, y contains the sum of the pixels in 0 ~ x-1 and 0 ~ y-1\n",
    "    ii_integral_image = np.zeros(i_origianl.shape)\n",
    "    s = np.zeros(i_origianl.shape)\n",
    "    for j in range(len(i_origianl)): # y\n",
    "        for i in range(len(i_origianl[j])): # x\n",
    "            s[j][i] = s[j-1][i] + i_origianl[j][i] if j-1 >= 0 else i_origianl[j][i]\n",
    "            ii_integral_image[j][i] = ii_integral_image[j][i-1]+s[j][i] if i-1 >= 0 else s[j][i]\n",
    "    return ii_integral_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSum(ii_integral_image, i, j, x, y):\n",
    "    # (A+B+C+D) + (A) - (A+B) - (A+C)\n",
    "    return (ii_integral_image[j+y][i+x] + ii_integral_image[j][i]) - (ii_integral_image[j+y][i] + ii_integral_image[j][i+x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VJFaceDetector:\n",
    "    def __init__(self, t):\n",
    "        \n",
    "        self.rounds = t\n",
    "        self.alphas = []\n",
    "        self.polarities = []\n",
    "        self.thresholds = []\n",
    "        \n",
    "        self.feature_coord = []\n",
    "\n",
    "        self.classifiers = []\n",
    "        self.classifier_type = []\n",
    "        self.top10_classifiers = []\n",
    "        self.top10_classifier_type = []\n",
    "        \n",
    "        self.accuracy = []\n",
    "        self.fpr = [] # false positiver\n",
    "        self.fnr = [] # false negative\n",
    "        self.tpr = []\n",
    "        self.tnr = []\n",
    "        \n",
    "    def makeHaarFeatures(self, ii_integral_image, n_featureTypes, flag):\n",
    "        total_width, total_height = ii_integral_image.shape # currently (19 by 19)\n",
    "        Haar_features = []\n",
    "        n_HarrType = {f:0 for f in range(1,n_featureTypes+1,1)}\n",
    "        for i in range(1, total_width+1):\n",
    "            for j in range(1, total_height+1):\n",
    "                w = 0\n",
    "                while i+w < total_width and w < 10: # set feature size\n",
    "                    h = 0\n",
    "                    while j+h < total_height and h < 10:\n",
    "\n",
    "                        # i : left top x coord\n",
    "                        # j : left top y coord\n",
    "                        # i+w : right bottom x coord\n",
    "                        # j+h : right bottom y coord\n",
    "\n",
    "                        current = computeSum(ii_integral_image, i, j, w, h) # find current area sum\n",
    "\n",
    "                        # feature type 1\n",
    "                        # two vertical rectangle feature\n",
    "                        if j+2*h < total_height:\n",
    "                            vertical_1 = computeSum(ii_integral_image, i, j+h, w, h)\n",
    "                            Haar_features.append(current-vertical_1)\n",
    "                            if not flag:\n",
    "                                n_HarrType[1] += 1\n",
    "                                self.feature_coord.append((\"Two Vertical\", [[i,j,w,h]],[[i,j+h,w,h]]))\n",
    "\n",
    "                        # feature type 2\n",
    "                        # two horizontal rectangle feature\n",
    "                        if i + 2*w < total_width:\n",
    "                            horizontal_1 = computeSum(ii_integral_image, i+w, j, w, h)\n",
    "                            Haar_features.append(horizontal_1-current) # compare the sum of two rectangles\n",
    "                            if not flag:\n",
    "                                n_HarrType[2] += 1\n",
    "                                self.feature_coord.append((\"Two Horizontal\", [[i+w,j,w,h]],[[i,j,w,h]]))\n",
    "\n",
    "                        # feature type 3\n",
    "                        # three horizontal rectangle feature      \n",
    "                        if i+3*w < total_width:    \n",
    "                            horizontal_2 = computeSum(ii_integral_image, i+2*w, j, w, h)\n",
    "                            Haar_features.append(horizontal_1-(horizontal_2+current))\n",
    "                            if not flag:\n",
    "                                n_HarrType[3]+=1\n",
    "                                self.feature_coord.append((\"Three Horizontal\",[[i+w, j, w, h]],[[i+2*w, j, w, h],[i,j,w,h]]))\n",
    "\n",
    "                        # feature type 4\n",
    "                        # three vertical rectangle feature    \n",
    "                        if j+3*h < total_height:    \n",
    "                            vertical_2 = computeSum(ii_integral_image, i, j+2*h, w, h)\n",
    "                            Haar_features.append(vertical_1-(vertical_2+current))\n",
    "                            if not flag:\n",
    "                                n_HarrType[4]+=1\n",
    "                                self.feature_coord.append((\"Three Vertical\",[[i, j+h, w, h]],[[i, j+2*h, w, h],[i,j,w,h]]))\n",
    "\n",
    "                        # feature type 5\n",
    "                        # Four diagonal rectangle feature\n",
    "                        if i+2*w < total_width and j+2*h < total_height:\n",
    "                            diagonal = computeSum(ii_integral_image,i+w,j+h,w,h)\n",
    "                            Haar_features.append((horizontal_1+vertical_1)-(current+diagonal))\n",
    "                            if not flag:\n",
    "                                n_HarrType[5] += 1\n",
    "                                self.feature_coord.append((\"Four Rectangle\", [[i+w,j,w,h],[i,j+h,w,h]],[[i,j,w,h],[i+w,j+h,w,h]]))\n",
    "                        \n",
    "                        # feature type 6\n",
    "                        # Doughnut feature\n",
    "                        if i+1 < total_width and j+1 < total_height:\n",
    "                            if w-2>=0 and h-2>= 0:\n",
    "                                center = computeSum(ii_integral_image,i+1,j+1,w-2,h-2)\n",
    "                                Haar_features.append((current)-center)\n",
    "                                if not flag:\n",
    "                                    n_HarrType[6] += 1\n",
    "                                    self.feature_coord.append((\"Doughnut\", [[i+1,j+1,w-2,h-2]],[[i,j,w,h]]))\n",
    "\n",
    "                        h += 1\n",
    "                    w += 1\n",
    "\n",
    "        return Haar_features, n_HarrType, flag\n",
    "    \n",
    "    def extractingHaarFeatures(self, train_data):\n",
    "        \n",
    "        flag = 0\n",
    "        n_featureTypes = 5\n",
    "        \n",
    "        self.weights = np.zeros(len(train_data))\n",
    "        \n",
    "        y_data = []\n",
    "        \n",
    "        l_positive=0 # number of face images\n",
    "        m_negative=0 # number of non-face images\n",
    "        \n",
    "        \n",
    "        # save true label (y_data)\n",
    "        for idx in tqdm(range(len(train_data))): # idx is the index of data point\n",
    "            if train_data[idx][1]==1:\n",
    "                l_positive+=1\n",
    "            elif train_data[idx][1]==0:\n",
    "                m_negative+=1\n",
    "            y_data.append(train_data[idx][1])\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        for idx in range(len(train_data)):\n",
    "            \n",
    "            self.weights[idx] = 1/(2*l_positive) if train_data[idx][1]==1 else 1/(2*m_negative)\n",
    "            # 1/2*(# label)\n",
    "            ii_integral_image = integralImage(train_data[idx][0])\n",
    "            \n",
    "            # make Haar features per sample image\n",
    "            Haar_features, n_HarrType, flag = self.makeHaarFeatures(ii_integral_image, n_featureTypes, flag)\n",
    "            \n",
    "            features.append(Haar_features)\n",
    "            if not flag: # show how many types are calculated\n",
    "                print(\"Number of each Harr feature types\")\n",
    "                for ty in range(1,n_featureTypes+1,1):\n",
    "                    print(\"Type {}: {}\".format(ty,n_HarrType[ty]))\n",
    "            flag=1\n",
    "        \n",
    "        x_data=list(map(list, zip(*features)))\n",
    "        print(\"The number of Haar features generated is {} and the size of training data is {}\".format(len(x_data),len(x_data[0])))\n",
    "        \n",
    "        return x_data, y_data\n",
    "    \n",
    "    \n",
    "    \n",
    "    def training(self, testing, x_data, y_data):\n",
    "        \n",
    "        for t in range(self.rounds):\n",
    "            w_data = self.weights\n",
    "            print(\"\\nIteration round : {}/{}\".format(t+1,self.rounds))\n",
    "            \n",
    "            # Normalize the weights\n",
    "            w_data = w_data / np.linalg.norm(w_data)\n",
    "            \n",
    "            n_features = len(self.feature_coord)\n",
    "            \n",
    "            best_classifier, best_classifier_index, best_classifier_type, best_error, best_accuracy = None, None, None, float('inf'), None\n",
    "            best_threshold_for_all, best_polarity_for_all = None, None\n",
    "            \n",
    "            total_pos=0\n",
    "            total_neg=0\n",
    "            for w, y in zip(w_data, y_data):\n",
    "                if y==1:\n",
    "                    total_pos += w\n",
    "                else:\n",
    "                    total_neg += w\n",
    "                    \n",
    "            # find best feature\n",
    "            error_feature = []\n",
    "            for feature_index, feature in enumerate(x_data): # feature is comparison value\n",
    "                # feature on every data point\n",
    "                feature_sorted = sorted(zip(w_data, feature, y_data), key=lambda x: x[1])\n",
    "                \n",
    "                \n",
    "                p_sum, n_sum = 0, 0\n",
    "                p_weights, n_weights = 0, 0\n",
    "                min_error, best_feature, best_feature_type, best_threshold, best_ploarity = float('inf'), None, None, None, None\n",
    "                \n",
    "                # find polarity and threshold for feature j\n",
    "                for w, f, y in feature_sorted:\n",
    "                    error = min(total_pos + n_weights - p_weights, total_neg - n_weights + p_weights)\n",
    "                    if error < min_error:\n",
    "                        min_error = error\n",
    "                        \n",
    "                        \n",
    "                        # bring feature coordinates\n",
    "                        best_feature_type, best_feature = self.feature_coord[feature_index][0], self.feature_coord[feature_index][1:]\n",
    "                        best_feature_index = feature_index\n",
    "                        best_threshold = f # rectangle sum difference\n",
    "                        best_polarity = 1 if p_sum > n_sum else -1\n",
    "                        \n",
    "                    \n",
    "                    if y == 1:\n",
    "                        p_sum += 1\n",
    "                        p_weights += w\n",
    "                    else:\n",
    "                        n_sum += 1\n",
    "                        n_weights += w\n",
    "                        \n",
    "                # find Empirical Risk Error (ERM) over decision stumps (hypothesis h) of feature j using its polarity adn threshold\n",
    "                # weak classifier\n",
    "                error, accuracy = 0, []\n",
    "                for idx, w in enumerate(w_data):\n",
    "                    if best_polarity * x_data[best_feature_index][idx] < best_polarity * best_threshold:\n",
    "                        hj=1\n",
    "                    else:\n",
    "                        hj=0\n",
    "                    correctness = abs(hj-y_data[idx])\n",
    "                    accuracy.append(correctness)\n",
    "                    error += w*correctness\n",
    "                    \n",
    "                error = error / len(y_data)\n",
    "                \n",
    "                \n",
    "                # find best classifier for all features\n",
    "                if error < best_error:\n",
    "                    best_classifier, best_classifier_index, best_error, best_accuracy = best_feature, best_feature_index, error, accuracy\n",
    "                    best_classifier_type = best_feature_type\n",
    "                    best_threshold_for_all, best_polarity_for_all = best_threshold, best_polarity\n",
    "                \n",
    "                error_feature.append([error, best_feature_type, best_feature])\n",
    "            \n",
    "            error_feature.sort(key=lambda x: x[0])\n",
    "            self.top10_classifiers.append(error_feature[:10])\n",
    "            \n",
    "            #calculate alpha and beta values for the round\n",
    "            if best_error==0:\n",
    "                best_error=0.01\n",
    "            print(\"The best Error is {}\".format(best_error))\n",
    "            \n",
    "            beta = best_error / (1.0 - best_error)\n",
    "            alpha = math.log(1.0/beta)\n",
    "            \n",
    "            # update the weights\n",
    "            for idx in range(len(best_accuracy)):\n",
    "                w_data[idx] = w_data[idx] * (beta ** (1 - best_accuracy[idx]))\n",
    "            \n",
    "            # store the trained values\n",
    "            self.classifiers.append(best_classifier)\n",
    "            self.classifier_type.append(best_classifier_type)\n",
    "            \n",
    "            self.alphas.append(alpha)\n",
    "            self.thresholds.append(best_threshold_for_all)\n",
    "            self.polarities.append(best_polarity_for_all)\n",
    "            self.weights = w_data\n",
    "            \n",
    "            print(\"The best classifier {} is in coordinate {} and threshold is {}\".format(best_classifier_type, best_classifier, best_threshold_for_all))\n",
    "            \n",
    "            fp_sum, fn_sum, acc = self.evaluation(testing)\n",
    "        return fp_sum, fn_sum, acc\n",
    "    \n",
    "    def classification(self, image):\n",
    "        \n",
    "        test_result = 0\n",
    "        ii_integral_image = integralImage(image)\n",
    "        for alpha, classifier, polarity, threshold in zip(self.alphas, self.classifiers, self.polarities, self.thresholds):\n",
    "            feature_extraction_test = 0\n",
    "            \n",
    "            for pos_reg in classifier[0]:\n",
    "                feature_extraction_test += computeSum(ii_integral_image, pos_reg[0], pos_reg[1], pos_reg[2], pos_reg[3])\n",
    "            for neg_reg in classifier[1]:\n",
    "                feature_extraction_test -= computeSum(ii_integral_image, neg_reg[0], neg_reg[1], neg_reg[2], neg_reg[3])\n",
    "            \n",
    "            prediction = 0\n",
    "            if polarity*feature_extraction_test < polarity*threshold:\n",
    "                prediction = 1\n",
    "            test_result += alpha * prediction\n",
    "        return test_result/sum(self.alphas), 1 if test_result >= 0.5*sum(self.alphas) else 0\n",
    "    \n",
    "    def evaluation(self, test_data):\n",
    "        p_sum = 0.0001\n",
    "        n_sum = 0.0001\n",
    "        \n",
    "        tp_sum = 0\n",
    "        tn_sum = 0\n",
    "        fp_sum = 0\n",
    "        fn_sum = 0\n",
    "        \n",
    "        for x, y in test_data:\n",
    "            \n",
    "            if y==1:\n",
    "                p_sum += 1\n",
    "            else:\n",
    "                n_sum += 1\n",
    "            \n",
    "            pp, pred = self.classification(x)\n",
    "            \n",
    "            if pred==1 and y==0:\n",
    "                fp_sum += 1  \n",
    "            elif pred==0 and y==1:\n",
    "                fn_sum += 1\n",
    "            elif pred==1 and y==1:\n",
    "                tp_sum += 1\n",
    "            else:\n",
    "                tn_sum += 1\n",
    "        correct = tp_sum+tn_sum\n",
    "        self.fpr.append(fp_sum/(fp_sum+tn_sum))\n",
    "        self.fnr.append(fn_sum/(fn_sum+tp_sum))\n",
    "        self.tpr.append(tp_sum/(tp_sum+fn_sum))\n",
    "        \n",
    "        self.accuracy.append(correct/len(test_data))\n",
    "        \n",
    "        print(\"false positive rate: %d/%d\\t(%f)\" % (fp_sum, n_sum, fp_sum/n_sum))\n",
    "        print(\"false negative rate: %d/%d\\t(%f)\" % (fn_sum, p_sum, fn_sum/p_sum))\n",
    "        print(\"\\t   accuracy: %d/%d\\t(%f)\" % (correct, len(test_data), correct/len(test_data)))\n",
    "        \n",
    "        return fp_sum, fn_sum, correct/len(test_data)\n",
    "    \n",
    "    \n",
    "    def confusion_matrix(self, test_y, predictions):\n",
    "        tp_sum = 0\n",
    "        tn_sum = 0\n",
    "        fp_sum = 0\n",
    "        fn_sum = 0\n",
    "        \n",
    "        for y, pred in zip(test_y,predictions):\n",
    "            \n",
    "            if pred==1 and y==1:\n",
    "                tp_sum += 1\n",
    "            elif pred==1 and y==0:\n",
    "                fp_sum += 1\n",
    "            elif pred==0 and y==1:\n",
    "                fn_sum += 1\n",
    "            else:\n",
    "                tn_sum += 1\n",
    "#         print(\"TP = {}\\nFP = {}\\nTN = {}\\nFN = {}\".format(tp_sum, fp_sum, tn_sum, fn_sum))\n",
    "#         print(\"Precision = {}\".format(str(tp_sum / (tp_sum + fp_sum))))\n",
    "#         print(\"Recall = {}\".format(str(tp_sum / (fn_sum + tp_sum))))\n",
    "        return tp_sum, fp_sum, tn_sum, fn_sum   \n",
    "    \n",
    "    def roc_curve(self, test_data):\n",
    "        x = []\n",
    "        y = []\n",
    "        for i in range(100):\n",
    "            threshold = 0.01 * i\n",
    "            test_x = [tp[0] for tp in test_data]\n",
    "            test_y = [tp[1] for tp in test_data]\n",
    "            bool_predictions = [self.classification(p)[1] for p in test_x]\n",
    "            print(\"Threshold = {}\".format(threshold))\n",
    "            test_y = [tp[1] for tp in testing]\n",
    "            TP, FP, TN, FN = self.confusion_matrix(test_y, bool_predictions)\n",
    "            TPR = TP / (TP + FN)\n",
    "            FPR = FP / (FP + TN)\n",
    "#             self.tpr.append(TPR)\n",
    "#             self.fpr.append(FPR)\n",
    "            x.append(FPR)\n",
    "            y.append(TPR)\n",
    "        plt.plot(x, y)\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC Curve\")\n",
    "        plt.show()\n",
    "        return x, y\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "req_rounds = [1, 3, 5, 10]\n",
    "final_accuracy, final_fp, final_fn = [], [], []\n",
    "t=10\n",
    "with open(\"training_data.pkl\", 'rb') as f:\n",
    "    training = pickle.load(f)\n",
    "    print(\"Training data size : \",len(training))\n",
    "    \n",
    "    with open('testing_data.pkl', 'rb') as ff:\n",
    "        testing = pickle.load(ff)\n",
    "    \n",
    "        VJFD = VJFaceDetector(t)\n",
    "        x_train_data, y_train_data = VJFD.extractingHaarFeatures(training)\n",
    "        print(\"Haar Features are generated\")\n",
    "\n",
    "        TE_fp, TE_fn, TE_correctness = VJFD.training(testing, x_train_data, y_train_data) #result is stored in self variables\n",
    "        \n",
    "        \n",
    "        print(\"Face-Detector finished training\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "i=0\n",
    "tmp_image=[]\n",
    "\n",
    "for alpha, polarity, threshold, classifier, classifier_type,  in zip(VJFD.alphas, VJFD.polarities, VJFD.thresholds, VJFD.classifiers, VJFD.classifier_type):\n",
    "    print(\"Results at round {}/{} \".format(i+1,10))\n",
    "    print(\"Best feature type : \",classifier_type)\n",
    "    print(\"Best feature coordinates : \", classifier)\n",
    "    print(\"Threshold : \", threshold)\n",
    "    \n",
    "    print(\"Evaluation\")\n",
    "    print(\"False Positive Rate : \", VJFD.fpr[i])\n",
    "    print(\"False Negative Rate : \", VJFD.fnr[i])\n",
    "    print(\"\\t    Accuracy : \", VJFD.accuracy[i])\n",
    "    \n",
    "    sample_image = Image.open('../VJ_dataset/trainset/faces/face00001.png')\n",
    "    img_features = ImageDraw.Draw(sample_image)\n",
    "    \n",
    "    for n_coord in classifier[1]:\n",
    "        n_area =[(n_coord[0],n_coord[1]),(n_coord[0]+n_coord[2],n_coord[1]+n_coord[3])]\n",
    "        img_features.rectangle(n_area, fill =\"blue\")\n",
    "        \n",
    "    for p_coord in classifier[0]:\n",
    "        p_area=[(p_coord[0],p_coord[1]),(p_coord[0]+p_coord[2],p_coord[1]+p_coord[3])]\n",
    "        img_features.rectangle(p_area, fill =\"yellow\")\n",
    "    #imshow(np.asarray(report_image))  \n",
    "    tmp_image.append(np.asarray(sample_image))\n",
    "    \n",
    "    i+=1\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find top 10 features selected by AdaBoost\n",
    "i=1\n",
    "\n",
    "columns = 2\n",
    "rows = 5\n",
    "fig = plt.figure(figsize=(19, 19))\n",
    "for (error, typ, features) in VJFD.top10_classifiers[9]:\n",
    "    report_image = Image.open('../VJ_dataset/trainset/faces/face00002.png')\n",
    "    img1 = ImageDraw.Draw(report_image)\n",
    "    # pos = [i, j, w, h]\n",
    "    for neg in features[1]:\n",
    "        shape2=[(neg[0],neg[1]),(neg[0]+neg[2],neg[1]+neg[3])]\n",
    "        img1.rectangle(shape2, fill =\"blue\")\n",
    "    for pos in features[0]:\n",
    "        shape1=[(pos[0],pos[1]),(pos[0]+pos[2],pos[1]+pos[3])]\n",
    "        img1.rectangle(shape1, fill =\"yellow\")\n",
    "    print(error)\n",
    "    fig.add_subplot(rows,columns, i)\n",
    "    fig.tight_layout()\n",
    "    plt.imshow(report_image, cmap=plt.cm.BuPu_r)\n",
    "    plt.title(\"Top {} featue selected with error {}\".format(i,error))\n",
    "    \n",
    "    i+=1\n",
    "plt.savefig(\"top10/top10_round_{}.png\".format(i,t),dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve trial 1\n",
    "import sklearn.metrics as metrics\n",
    "test_x = [tp[0] for tp in testing]\n",
    "test_y = [tp[1] for tp in testing]\n",
    "bool_predictions = [VJFD.classification(p)[1] for p in test_x]\n",
    "fpr, tpr, threshold = metrics.roc_curve(test_y,bool_predictions)\n",
    "roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "plt.savefig(\"ROC_round_{}.png\".format(t),dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve trial 2\n",
    "x,y = VJFD.roc_curve(testing)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(x, y,s=10 )\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "# plt.xlim(0.0621,0.0622)\n",
    "# plt.ylim(0.0621,0.0622)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Top features for each round      \n",
    "columns = 2\n",
    "rows = 5\n",
    "fig = plt.figure(figsize=(19, 19))\n",
    "for i in range(1,len(tmp_image)+1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    imshow(tmp_image[i-1], cmap=plt.cm.BuPu_r)\n",
    "plt.show()\n",
    "\n",
    "x=[]\n",
    "for i in range(10):\n",
    "    x.append(i)\n",
    "\n",
    "plt.figure()\n",
    "# plt.subplot(211)\n",
    "plt.plot(x, VJFD.accuracy, 'k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel(\"Round\")\n",
    "plt.show()\n",
    "\n",
    "# plt.subplot(212)\n",
    "plt.plot(x, VJFD.fpr, 'r+', label='false_positives')\n",
    "plt.xlabel(\"Round\")\n",
    "\n",
    "# plt.subplot(212)\n",
    "plt.plot(x, VJFD.fnr, 'b--',label='false_negatives')\n",
    "#plt.legend(loc=\"upper right\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(0.6, 0.5))\n",
    "plt.xlabel(\"Round\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Haar_features = []\n",
    "feature_coord=[]\n",
    "n_featureTypes=6\n",
    "flag=0\n",
    "total_width = 19\n",
    "total_height = 19\n",
    "n_HarrType = {f:0 for f in range(1,n_featureTypes+1,1)}\n",
    "for i in range(1, total_width+1):\n",
    "    for j in range(1, total_height+1):\n",
    "        w = 0\n",
    "        while i+w < total_width and w < 10: # set feature size\n",
    "            h = 0\n",
    "            while j+h < total_height and h < 10:\n",
    "\n",
    "                # i : left top x coord\n",
    "                # j : left top y coord\n",
    "                # i+w : right bottom x coord\n",
    "                # j+h : right bottom y coord\n",
    "\n",
    "                current = computeSum(ii_integral_image, i, j, w, h) # find current area sum\n",
    "\n",
    "                # feature type 1\n",
    "                # two vertical rectangle feature\n",
    "#                 if j+2*h < total_height:\n",
    "#                     vertical_1 = computeSum(ii_integral_image, i, j+h, w, h)\n",
    "#                     Haar_features.append(current-vertical_1)\n",
    "#                     if not flag:\n",
    "#                         n_HarrType[1] += 1\n",
    "# #                         feature_coord.append((\"Two Vertical\", [[i,j,w,h]],[[i,j+h,w,h]]))\n",
    "#                 # feature type 2\n",
    "#                 # two horizontal rectangle feature\n",
    "#                 if i + 2*w < total_width:\n",
    "#                     horizontal_1 = computeSum(ii_integral_image, i+w, j, w, h)\n",
    "#                     Haar_features.append(horizontal_1-current) # compare the sum of two rectangles\n",
    "#                     if not flag:\n",
    "#                         n_HarrType[2] += 1\n",
    "#                         feature_coord.append((\"Two Horizontal\", [[i+w,j,w,h]],[[i,j,w,h]]))\n",
    "\n",
    "#                 # feature type 3\n",
    "#                 # three horizontal rectangle feature      \n",
    "#                 if i+3*w < total_width:    \n",
    "#                     horizontal_2 = computeSum(ii_integral_image, i+2*w, j, w, h)\n",
    "#                     Haar_features.append(horizontal_1-(horizontal_2+current))\n",
    "#                     if not flag:\n",
    "#                         n_HarrType[3]+=1\n",
    "#                         feature_coord.append((\"Three Horizontal\",[[i+w, j, w, h]],[[i+2*w, j, w, h],[i,j,w,h]]))\n",
    "\n",
    "#                 # feature type 4\n",
    "#                 # three vertical rectangle feature    \n",
    "#                 if j+3*h < total_height:    \n",
    "#                     vertical_2 = computeSum(ii_integral_image, i, j+2*h, w, h)\n",
    "#                     Haar_features.append(vertical_1-(vertical_2+current))\n",
    "#                     if not flag:\n",
    "#                         n_HarrType[4]+=1\n",
    "#                         feature_coord.append((\"Three Vertical\",[[i, j+h, w, h]],[[i, j+2*h, w, h],[i,j,w,h]]))\n",
    "\n",
    "                # feature type 5\n",
    "                # Four diagonal rectangle feature\n",
    "#                 if i+2*w < total_width and j+2*h < total_height:\n",
    "#                     diagonal = computeSum(ii_integral_image,i+w,j+h,w,h)\n",
    "#                     Haar_features.append((horizontal_1+vertical_1)-(current+diagonal))\n",
    "#                     if not flag:\n",
    "#                         n_HarrType[5] += 1\n",
    "#                         feature_coord.append((\"Four Rectangle\", [[i+w,j,w,h],[i,j+h,w,h]],[[i,j,w,h],[i+w,j+h,w,h]]))\n",
    "                \n",
    "                # feature type 6\n",
    "                # Four reverse diagonal rectangle feature\n",
    "                if i+1 < total_width and j+1 < total_height:\n",
    "                    if w-2>=0 and h-2>= 0:\n",
    "                        center = computeSum(ii_integral_image,i+1,j+1,w-2,h-2)\n",
    "                        Haar_features.append((current)-center)\n",
    "                        if not flag:\n",
    "                            n_HarrType[6] += 1\n",
    "                            feature_coord.append((\"Doughnut\", [[i+1,j+1,w-2,h-2]],[[i,j,w,h]]))\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                h += 1\n",
    "            w += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image, ImageDraw\n",
    "# import matplotlib.pyplot as plt\n",
    "training[0]\n",
    "ii_integral_image = integralImage(training[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_image = []\n",
    "report_image = None\n",
    "for (ty, r1, r2) in feature_coord:\n",
    "    report_image = Image.open('../VJ_dataset/trainset/faces/face00002.png')\n",
    "    img1 = ImageDraw.Draw(report_image)\n",
    "    # pos = [i, j, w, h]\n",
    "    for neg in r2:\n",
    "        shape2=[(neg[0],neg[1]),(neg[0]+neg[2],neg[1]+neg[3])]\n",
    "        img1.rectangle(shape2, fill =\"blue\")\n",
    "    for pos in r1:\n",
    "        shape1=[(pos[0],pos[1]),(pos[0]+pos[2],pos[1]+pos[3])]\n",
    "        img1.rectangle(shape1, fill =\"yellow\")\n",
    "    \n",
    "    plt.imshow(report_image,cmap=plt.cm.BuPu_r)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
